---
main:
  run: |
    set((m) => {
      m.chat.winOnEnd = true;
      level.content = level.code["Screen.example.js"];
    });
  messages:
  - todas las tareas que completamos antes estaban relacionadas con nuestro üåÄ  n√∫cleo del emulador
  - y hasta ahora evit√© intencionalmente hablar sobre el üå∏  frontend del emulador ya que es <dependiente de la plataforma>
  - pero hagamos una revisi√≥n r√°pida de c√≥mo funciona
  - nuestro frontend est√° hecho con üåê  <tecnolog√≠as web>
  - para mostrar p√≠xeles, inicializamos un elemento ```raw <canvas />``` que el m√©todo `setBuffer(...)` llena usando el frame buffer (una matriz de p√≠xeles __$AABBGGRR__) que genera la üñ•Ô∏è  PPU
  responses:
  - correcto, ¬øy qu√© hay del audio? üîä [audio]

audio:
  run: |
    set(() => {
      level.content = level.code["audioWorklet.example.js"];
    });
    bus.emit("content-changed");
  messages:
  - para el audio, creamos un procesador <audio worklet> que puede recibir samples del emulador y colocarlos en un <ring buffer> üíç
  - cada vez que el dispositivo de audio <necesita> m√°s samples, se llama a `process(...)`, donde extraemos del ring buffer y los proporcionamos
  - tambi√©n solicitamos al emulador m√°s samples, lo cual es importante cuando estamos <sincronizando con el audio>
  responses:
  - ¬øsincronizando con... <el audio>? ü§î [syncmethods]

syncmethods:
  messages:
  - "b√°sicamente, podemos ejecutar nuestro emulador de dos maneras:"
  - "üìπ  <Sincronizar con video>: emulamos frames completos, sincronizando la ejecuci√≥n con nuestra pantalla"
  - "üîä  <Sincronizar con audio>: emulamos <N> samples cada vez que el dispositivo de audio los solicita"
  - ambos m√©todos tienen sus pros y sus contras, pero en general <sincronizar con audio> es preferido y da mejores resultados
  responses:
  - (*) ¬øc√≥mo puedo sincronizar con video? [synctovideo]
  - (*) ¬øc√≥mo puedo sincronizar con audio? [synctoaudio]
  - mu√©strame un ejemplo üîç [example]

synctovideo:
  run: |
    set(() => {
      level.content = level.code["FrameTimer.example.js"];
    });
    bus.emit("content-changed");
  messages:
  - llamamos a `requestAnimationFrame(...)` para recibir una notificaci√≥n cuando podamos actualizar la pantalla
  - luego, si han pasado <16.66 ms> (~1000~ / 60) desde la √∫ltima vez, solicitamos a nuestro n√∫cleo del emulador un nuevo frame con `onFrame()`
  - despu√©s de generar el nuevo frame, podemos actualizar nuestro canvas de p√≠xeles y enviar los nuevos samples de audio
  - "‚ö†Ô∏è  esa √∫ltima parte requiere <atenci√≥n especial> al sincronizar con video:"
  - si el emulador gener√≥ m√°s samples de los necesarios debido a imprecisiones de tiempo (por ejemplo, 740 samples en lugar de 735 (~44100~ / 60)), ese fragmento debe ser <resampleado> para evitar sobrecargar el ring buffer (provocando fallos de audio)
  - |-
    el c√≥digo del frontend se ver√≠a as√≠:
      ```javascript this.frameTimer = new FrameTimer(() => {
        // <<update input here>>

        if (syncToVideo) {
          // ejecutar por un cuadro completo
          this.emulator.frame(); // env√≠a los p√≠xeles al canvas

          if (this.samples.length !== 735)
            this.samples = this._resample(this.samples, 735);

          this._updateAudio(); // env√≠a los samples al audio worklet
        }
      });```
  responses:
  - ...syncmethods

synctoaudio:
  run: |
    set(() => {
      level.content = level.code["Speaker.example.js"];
    }); 
    bus.emit("content-changed");
  messages:
  - iniciamos un `AudioContext`, una instancia del worklet, y proporcionamos un m√©todo `writeSamples(...)` para que el emulador pueda enviar los samples
  - cada vez que el sistema de audio solicita m√°s samples, llamamos a `onAudioRequested({ need, have, target })`
  - el objetivo aqu√≠ es mantener el ring buffer lleno con `target` samples, que es la mitad del tama√±o del buffer, corrigiendo si es necesario
  - |-
    el c√≥digo del frontend se ver√≠a as√≠:
      ```javascript this.speaker = new Speaker(
        ({ need, have, target }) => {
          if (syncToAudio) {
            let n = need;
            if (have > target + 64) n--;
            else if (have < target - 64) n++;

            // ejecutar por n samples
            this.emulator.samples(n); // puede enviar p√≠xeles al canvas
          
            this._updateSound(); // env√≠a los samples al audio worklet
          }
        });```
  responses:
  - ...syncmethods

example:
  run: |
    set(() => {
      level.content = level.code["EmulatorFrontend.example.js"];
    });
    bus.emit("content-changed");
  messages:
  - aqu√≠ tienes un ejemplo de un frontend de emulador simplificado
  - interact√∫a con la clase `Emulator` que mostr√© en el nivel anterior
  - ¬°√©chale un vistazo!
  responses:
  - ‚ñ∂Ô∏è  continuar [end]
